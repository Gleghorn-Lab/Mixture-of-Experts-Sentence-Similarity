{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main --yaml_path yamls/protein_vec.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py --eval --yaml_path yamls/benchmarking/esm_sim_benchmark_8.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py --eval --yaml_path yamls/benchmarking/esm_sim_benchmark_35.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py --eval --yaml_path yamls/benchmarking/esm_sim_benchmark_150.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py --eval --yaml_path yamls/benchmarking/esm_sim_benchmark_650.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from models.model_zoo import *\n",
    "from utils import get_yaml\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yargs = get_yaml('yamls/SE/cvd.yaml')\n",
    "config = BertConfig.from_pretrained(yargs['general_args']['model_path'])\n",
    "for key, value in yargs['general_args'].items(): # copy yaml config into args\n",
    "    setattr(config, key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [path.replace('\\\\', '/') for path in glob('./weights/*.pt')]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for weight in weights:\n",
    "    model = torch.load(weight)\n",
    "    try:\n",
    "        model.config = model.bert.config\n",
    "    except:\n",
    "        print(weight)\n",
    "        continue\n",
    "    path = 'lhallee/' + weight.split('/')[-1].split('.pt')[0]\n",
    "    paths.append(path)\n",
    "    #model.push_to_hub(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('results/NLP_MOE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    tokenizer.push_to_hub(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('lhallee/sci_moe_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub('lhallee/all_nlp_singlemoe_MI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.protein_vec.src_run.huggingface_protein_vec import ProteinVec, ProteinVecConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_model.push_to_hub('lhallee/ProteinVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.0rc0 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\lhall\\Desktop\\Research\\Mixture-of-Experts-Sentence-Similarity\\models\\protein_vec\\src_run\\protein_vec_models\\tm_vec_swiss_model_large.ckpt`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.9.4 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\lhall\\Desktop\\Research\\Mixture-of-Experts-Sentence-Similarity\\models\\protein_vec\\src_run\\protein_vec_models\\aspect_vec_pfam.ckpt`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.9.4 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\lhall\\Desktop\\Research\\Mixture-of-Experts-Sentence-Similarity\\models\\protein_vec\\src_run\\protein_vec_models\\aspect_vec_gene3d.ckpt`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.9.4 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\lhall\\Desktop\\Research\\Mixture-of-Experts-Sentence-Similarity\\models\\protein_vec\\src_run\\protein_vec_models\\aspect_vec_ec.ckpt`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.9.4 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\lhall\\Desktop\\Research\\Mixture-of-Experts-Sentence-Similarity\\models\\protein_vec\\src_run\\protein_vec_models\\aspect_vec_go_mfo.ckpt`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.9.4 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\lhall\\Desktop\\Research\\Mixture-of-Experts-Sentence-Similarity\\models\\protein_vec\\src_run\\protein_vec_models\\aspect_vec_go_bpo.ckpt`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.9.4 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\lhall\\Desktop\\Research\\Mixture-of-Experts-Sentence-Similarity\\models\\protein_vec\\src_run\\protein_vec_models\\aspect_vec_go_cco.ckpt`\n"
     ]
    }
   ],
   "source": [
    "disk_model = ProteinVec(config=ProteinVecConfig())\n",
    "disk_model.load_from_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.load('models/protein_vec/src_run/protein_vec_models/protein_vec.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in test['state_dict'].items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f139d61bbf4fa4a230086f9ab67ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_model = ProteinVec.from_pretrained('lhallee/ProteinVec', config=ProteinVecConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models are equal.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def are_models_equal(model1, model2):\n",
    "    state_dict1 = model1.state_dict()\n",
    "    state_dict2 = model2.state_dict()\n",
    "    \n",
    "    if len(state_dict1) != len(state_dict2):\n",
    "        print('Length')\n",
    "        return False\n",
    "    \n",
    "    for key in state_dict1:\n",
    "        if key not in state_dict2:\n",
    "            print('Key')\n",
    "            return False\n",
    "        \n",
    "        if not torch.equal(state_dict1[key], state_dict2[key]):\n",
    "            print('Equal')\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "if are_models_equal(disk_model.cpu(), hf_model.cpu()):\n",
    "    print(\"The models are equal.\")\n",
    "else:\n",
    "    print(\"The models are not equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #encoder_state_dict = OrderedDict()\n",
    "        #for key, value in state_dict.items():\n",
    "        #    if key.startswith('encoder.'):\n",
    "        #        new_key = key[len('encoder.'):]  # Remove 'encoder.' prefix\n",
    "        #        encoder_state_dict[new_key] = value\n",
    "        #    else:\n",
    "        #        encoder_state_dict[key] = value#\n",
    "        #self.moe.encoder.load_state_dict(encoder_state_dict)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
