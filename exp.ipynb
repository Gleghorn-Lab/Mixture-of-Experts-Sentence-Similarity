{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertModel, EvalPrediction\n",
    "from models.modeling_moebert import MoEBertForSentenceSimilarity, BertForSentenceSimilarity\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, hamming_loss, confusion_matrix\n",
    "from models.load_model import MoEBertLoadWeights\n",
    "from data_zoo import *\n",
    "from utils import get_yaml, log_metrics\n",
    "from trainer import HF_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSentenceSimilarity(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {\n",
    "    'domains': ['TEST'],\n",
    "    'new_special_tokens': True,\n",
    "    'num_experts': 4,\n",
    "    'topk': 2,\n",
    "    'token_moe':False,\n",
    "    'moe_type':'topk',\n",
    "    'num_tasks':2,\n",
    "    'wBAL':0.1,\n",
    "    'wMI':0.1\n",
    "}\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "base_model = BertModel.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "#loader = MoEBertLoadWeights(args, base_model=base_model, tokenizer=tokenizer)\n",
    "#base_model, tokenizer = loader.get_seeded_model()\n",
    "#model = MoEBertForSentenceSimilarity(args, base_model)\n",
    "model = BertForSentenceSimilarity(base_model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yargs = get_yaml('yamls/base.yaml')['training_args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "for i in range(20, 410, 20):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "batch_sentences = [\n",
    "    'Hello, how are you?',\n",
    "    'I am doing well, thank you!',\n",
    "    'The weather is nice today.',\n",
    "]\n",
    "\n",
    "ids = tokenizer(batch_sentences, return_tensors='pt', padding=True, truncation=True)\n",
    "router_labels = torch.tensor([1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_train(data_paths, tokenizer, domains, max_length=512):\n",
    "    train_a, train_b, train_c_label, train_r_label = [], [], [], []\n",
    "    valid_a, valid_b, valid_c_label, valid_r_label = [], [], [], []\n",
    "    test_a, test_b, test_c_label, test_r_label = [], [], [], []\n",
    "    for i, data_path in enumerate(data_paths):\n",
    "        dataset = load_dataset(data_path)\n",
    "        train = dataset['train']\n",
    "        valid = dataset['valid']\n",
    "        test = dataset['test']\n",
    "        train_a.extend(train['a'])\n",
    "        train_b.extend(train['b'])\n",
    "        train_c_label.extend(train['label'])\n",
    "        train_r_label.extend([i] * len(train['label']))\n",
    "        valid_a.extend(valid['a'])\n",
    "        valid_b.extend(valid['b'])\n",
    "        valid_c_label.extend(valid['label'])\n",
    "        valid_r_label.extend([i] * len(valid['label']))\n",
    "        test_a.extend(test['a'])\n",
    "        test_b.extend(test['b'])\n",
    "        test_c_label.extend(test['label'])\n",
    "        test_r_label.extend([i] * len(test['label']))\n",
    "    random.shuffle(valid_c_label)\n",
    "    train_dataset = TextDataset(train_a, train_b, train_c_label, train_r_label, tokenizer, domains, max_length)\n",
    "    valid_dataset = TextDataset(valid_a[:40], valid_b[:40], valid_c_label[:40], valid_r_label[:40], tokenizer, domains, max_length)\n",
    "    test_dataset = TextDataset(test_a, test_b, test_c_label, test_r_label, tokenizer, domains, max_length)\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = get_datasets_train(['lhallee/abstract_domain_skincancer'], tokenizer, ['TEST'], 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collator(features):\n",
    "    batch = {key: torch.stack([f[key] for f in features]) for key in features[0]}\n",
    "    return batch\n",
    "\n",
    "\n",
    "def calculate_max_metrics(ss, labels, cutoff):\n",
    "    ss, labels = ss.float(), labels.float()\n",
    "    tp = torch.sum((ss >= cutoff) & (labels == 1.0))\n",
    "    fp = torch.sum((ss >= cutoff) & (labels == 0.0))\n",
    "    fn = torch.sum((ss < cutoff) & (labels == 1.0))\n",
    "    precision_denominator = tp + fp\n",
    "    precision = torch.where(precision_denominator != 0, tp / precision_denominator, torch.tensor(0.0))\n",
    "    recall_denominator = tp + fn\n",
    "    recall = torch.where(recall_denominator != 0, tp / recall_denominator, torch.tensor(0.0))\n",
    "    f1 = torch.where((precision + recall) != 0, (2 * precision * recall) / (precision + recall), torch.tensor(0.0))\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n",
    "def max_metrics(ss, labels, increment=0.01):\n",
    "    ss = torch.clamp(ss, -1.0, 1.0)\n",
    "    min_val = ss.min().item()\n",
    "    max_val = 1\n",
    "    if min_val >= max_val:\n",
    "        min_val = 0\n",
    "    cutoffs = torch.arange(min_val, max_val, increment)\n",
    "    metrics = [calculate_max_metrics(ss, labels, cutoff.item()) for cutoff in cutoffs]\n",
    "    f1s = torch.tensor([metric[0] for metric in metrics])\n",
    "    precs = torch.tensor([metric[1] for metric in metrics])\n",
    "    recalls = torch.tensor([metric[2] for metric in metrics])\n",
    "    valid_f1s = torch.where(torch.isnan(f1s), torch.tensor(-1.0), f1s)  # Replace NaN with -1 to ignore them in argmax\n",
    "    max_index = torch.argmax(valid_f1s)\n",
    "    return f1s[max_index].item(), precs[max_index].item(), recalls[max_index].item(), cutoffs[max_index].item()\n",
    "\n",
    "\n",
    "def compute_metrics_sentence_similarity(p: EvalPrediction):\n",
    "    preds = p.predictions\n",
    "    labels = p.label_ids[-1]\n",
    "\n",
    "    print(preds[0].shape, preds[1].shape)\n",
    "    print(labels)\n",
    "\n",
    "    emb_a, emb_b = preds[0], preds[1]\n",
    "    # Convert embeddings to tensors\n",
    "    emb_a_tensor = torch.tensor(emb_a)\n",
    "    emb_b_tensor = torch.tensor(emb_b)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "\n",
    "    # Compute cosine similarity between the embeddings\n",
    "    cosine_sim = F.cosine_similarity(emb_a_tensor, emb_b_tensor)\n",
    "    # Compute max metrics\n",
    "    f1, prec, recall, thres = max_metrics(cosine_sim, labels_tensor)\n",
    "    # Compute accuracy based on the threshold found\n",
    "    predictions = (cosine_sim > thres).float()\n",
    "    acc = accuracy_score(predictions.flatten().numpy(), labels.flatten())\n",
    "    # Compute the mean absolute difference between cosine similarities and labels\n",
    "    dist = torch.mean(torch.abs(cosine_sim - labels_tensor)).item()\n",
    "    # Return a dictionary of the computed metrics\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1_max': f1,\n",
    "        'precision_max': prec,\n",
    "        'recall_max': recall,\n",
    "        'threshold': thres,\n",
    "        'distance': dist\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142982afbb054abc8dccb98d4d4031c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 768) (40, 768)\n",
      "[1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      "0.596491277217865 0.42500001192092896 1.0 0.46585744619369507 0.4 0.5347017645835876\n"
     ]
    }
   ],
   "source": [
    "trainer = HF_trainer(model, train_dataset, valid_dataset,\n",
    "                     compute_metrics=compute_metrics_sentence_similarity, data_collator=data_collator, **yargs)\n",
    "predictions, label_ids, metrics = trainer.predict(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_metrics('test.txt', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 52.1240119934082,\n",
       " 'test_accuracy': 0.4,\n",
       " 'test_f1_max': 0.596491277217865,\n",
       " 'test_precision_max': 0.42500001192092896,\n",
       " 'test_recall_max': 1.0,\n",
       " 'test_threshold': 0.46585744619369507,\n",
       " 'test_distance': 0.5347017645835876,\n",
       " 'test_runtime': 0.6754,\n",
       " 'test_samples_per_second': 59.22,\n",
       " 'test_steps_per_second': 2.961}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    hidden_size = 4\n",
    "    intermediate_size = 8\n",
    "    hidden_dropout_prob = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertExpert1(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.intermediate_up = nn.Linear(config.hidden_size, config.intermediate_size) # BertIntermediate dense\n",
    "        self.intermediate_down = nn.Linear(config.intermediate_size, config.hidden_size) # BertOutput dense\n",
    "        self.new_linear = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.act = nn.GELU()\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.act(self.intermediate_up(hidden_states)) * self.new_linear(hidden_states)\n",
    "        hidden_states = self.dropout(self.intermediate_down(hidden_states))\n",
    "        return hidden_states\n",
    "    \n",
    "\n",
    "class BertExpert2(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.intermediate_up = nn.Linear(config.hidden_size, config.intermediate_size) # BertIntermediate dense\n",
    "        self.intermediate_down = nn.Linear(config.intermediate_size, config.hidden_size) # BertOutput dense\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "        self.new_linear = nn.Linear(config.hidden_size, config.intermediate_size, bias=True)\n",
    "        self.new_linear.weight.data.zero_()\n",
    "        self.new_linear.bias.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.act(self.intermediate_up(hidden_states)) * self.new_linear(hidden_states)\n",
    "        hidden_states = self.dropout(self.intermediate_down(hidden_states))\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = torch.rand(2, 16, config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_up = nn.Linear(config.hidden_size, config.intermediate_size) # BertIntermediate dense\n",
    "intermediate_down = nn.Linear(config.intermediate_size, config.hidden_size) # BertOutput dense\n",
    "new_linear = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "new_linear.weight.data.zero_()\n",
    "new_linear.bias.data.fill_(1.0)\n",
    "out1 = intermediate_up(hidden_states) * new_linear(hidden_states)\n",
    "out2 = intermediate_up(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 == out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
