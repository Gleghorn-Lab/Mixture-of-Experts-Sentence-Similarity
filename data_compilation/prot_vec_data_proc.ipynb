{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from itertools import chain\n",
    "from tqdm.auto import tqdm\n",
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def load_df(path):\n",
    "    df = pd.read_csv(path, delimiter='\\t').rename(columns={\n",
    "        'EC number':'EC',\n",
    "        'Gene Ontology (molecular function)':'MF',\n",
    "        'Gene Ontology (biological process)':'BP',\n",
    "        'Gene Ontology (cellular component)':'CC',\n",
    "        'InterPro':'IP',\n",
    "        'Gene3D':'3D',\n",
    "        'Sequence':'seqs'\n",
    "    }).astype('string')\n",
    "    print(len(df))\n",
    "    df['combined'] = df.progress_apply(lambda x: ' '.join(str(x[col]) for col in df.columns if col != 'seqs'), axis=1)\n",
    "    df = df.sort_values(by='combined', key=lambda x: x.str.len(), ascending=False)\n",
    "    df = df.drop_duplicates(subset='seqs', keep='first')\n",
    "    df = df.drop('combined', axis=1)\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(len(df))\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_dictionary(input, start=1, name='ec'):\n",
    "    id2label, label2id = {}, {}\n",
    "    for index, entry in enumerate(input, start=start):\n",
    "        entry = entry + '_' + name\n",
    "        id2label[index] = entry\n",
    "        label2id[entry] = index\n",
    "    return id2label, label2id\n",
    "\n",
    "\n",
    "def process_descriptors(input_list,\n",
    "                        start=1,\n",
    "                        name='ec',\n",
    "                        id2label=None,\n",
    "                        label2id=None,\n",
    "                        filter_func=lambda d: d.strip()):\n",
    "    col_list, new_col = [], []\n",
    "\n",
    "    if id2label == None or label2id == None:\n",
    "        for item in tqdm(input_list, desc=f'{name} make dicts'):\n",
    "            descriptors = str(item).split(';')\n",
    "            filtered_descriptors = [filter_func(d) for d in descriptors]\n",
    "            filtered_descriptors = [d for d in filtered_descriptors if d and d.lower() != 'none' and d.lower() != 'nan']\n",
    "            col_list.extend(filtered_descriptors)\n",
    "        col_list = sorted(list(set(col_list)))\n",
    "        if '' in col_list:\n",
    "            col_list.remove('')\n",
    "        len_col_list = len(col_list)\n",
    "        id2label, label2id = create_dictionary(col_list, start=start, name=name)\n",
    "    else:\n",
    "        len_col_list = len(id2label.keys())\n",
    "\n",
    "    for item in tqdm(input_list, desc=f'{name} make new column'):\n",
    "        descriptors = str(item).split(';')\n",
    "        filtered_descriptors = [filter_func(d) for d in descriptors]\n",
    "        filtered_descriptors = [d for d in filtered_descriptors if d and d.lower() != 'none' and d.lower() != 'nan']\n",
    "        new_entry = [label2id[d + '_' + name] for d in filtered_descriptors if d] or [0]\n",
    "        new_col.append(new_entry)\n",
    "\n",
    "    return new_col, id2label, label2id, len_col_list + start\n",
    "\n",
    "\n",
    "def ec_processing(input_list, start=1, name='ec', id2label=None, label2id=None):\n",
    "    return process_descriptors(input_list, start=start, name=name, id2label=id2label, label2id=label2id,\n",
    "                               filter_func=lambda d: d.strip() if '-' not in d and 'n' not in d else '')\n",
    "\n",
    "\n",
    "def go_processing(input_list, start=1, name='go', id2label=None, label2id=None):\n",
    "    return process_descriptors(input_list, start=start, name=name, id2label=id2label, label2id=label2id,\n",
    "                               filter_func=lambda d: d[d.find('[GO:')+1:d.find(']')].strip())\n",
    "\n",
    "\n",
    "def cofactor_processing(input_list, start=1, name='co', id2label=None, label2id=None):\n",
    "    return process_descriptors(input_list, start=start, name=name, id2label=id2label, label2id=label2id,\n",
    "                               filter_func=lambda d: d[d.find('Name=')+5:].strip() if 'Name' in d else '')\n",
    "\n",
    "\n",
    "def domain_processing(input_list, start=1, name='ip', id2label=None, label2id=None):\n",
    "    return process_descriptors(input_list, start=start, name=name, id2label=id2label, label2id=label2id)\n",
    "\n",
    "\n",
    "def replace_df(df, all_cols):\n",
    "    new_ec_col, new_mf_col, new_bp_col, new_cc_col, new_ip_col, new_threed_col, new_co_col = all_cols\n",
    "    combined_list = [sorted([item for item in list(chain.from_iterable(element)) if item != 0])\n",
    "                     for element in zip(*all_cols) if element != [0]]\n",
    "\n",
    "    df['EC'] = new_ec_col\n",
    "    df['Cofactor'] = new_co_col\n",
    "    df['MF'] = new_mf_col\n",
    "    df['BP'] = new_bp_col\n",
    "    df['CC'] = new_cc_col\n",
    "    df['IP'] = new_ip_col\n",
    "    df['3D'] = new_threed_col\n",
    "    df['combined'] = combined_list\n",
    "    df['string_combined'] = df['combined'].astype('string')\n",
    "\n",
    "    unique_dict = {}\n",
    "\n",
    "    # Iterate over the DataFrame and update the dictionary\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        combined_value = row['string_combined']\n",
    "        if combined_value not in unique_dict:\n",
    "            unique_dict[combined_value] = row\n",
    "        if combined_value == '[0]':\n",
    "            print(combined_value)\n",
    "\n",
    "    # Create the final DataFrame from the dictionary values\n",
    "    df_final = pd.DataFrame(unique_dict.values()).drop(columns=['string_combined'])\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af26d97204b2420c9cbf41457a01f251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/461186 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec03a4f731484de3a2375e2341e77741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ec make dicts:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23599a4aa544295b9d9a0c5eb044207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ec make new column:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed15703d67244efb8a7d4a39b3ec35ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mf make dicts:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3c2dde55724ca8b831d505e4ff3705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mf make new column:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86664b9cfc4447ee84581066ff27ae73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bp make dicts:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3da3f16e25c46bfbd2d672c24c3ea20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bp make new column:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a01789d65ba4624aa9a7deecfe7ada9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cc make dicts:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3701e66c2e43ebae982d35776fccd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cc make new column:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34225f76854445a6aadc6572f24d6b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ip make dicts:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b82ace37df4126b8d9e226971dbc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ip make new column:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06da949a3484ac5adb5367dcdcb3c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3d make dicts:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe3f3f3180f4c0190f8a468f060dac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3d make new column:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ff069b219341318ba7c6a617e00e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "co make dicts:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec81f9572364d3c85d40599e3158c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "co make new column:   0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58945\n",
      "58945\n",
      "58945 58945\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4c18bb7ae74c77ad0be3aba43875e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/381212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94675\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "df = load_df('swiss_prot_raw.tsv')\n",
    "# EC\n",
    "ecs = df['EC'].tolist()\n",
    "new_ec_col, id2ec, ec2id, ec_len = ec_processing(ecs, name='ec', start=1)\n",
    "# MF\n",
    "mfs = df['MF'].tolist()\n",
    "new_mf_col, id2mf, mf2id, mf_len = go_processing(mfs, name='mf', start=ec_len+1)\n",
    "# BP\n",
    "bps = df['BP'].tolist()\n",
    "new_bp_col, id2bp, bp2id, bp_len = go_processing(bps, name='bp', start=mf_len+1)\n",
    "# CC\n",
    "ccs = df['CC'].tolist()\n",
    "new_cc_col, id2cc, cc2id, cc_len = go_processing(ccs, name='cc', start=bp_len+1)\n",
    "# IP\n",
    "ips = df['IP'].tolist()\n",
    "new_ip_col, id2ip, ip2id, ip_len = domain_processing(ips, name='ip', start=cc_len+1)\n",
    "# 3D\n",
    "threeds = df['3D'].tolist()\n",
    "new_threed_col, id2threed, threed2id, threed_len = domain_processing(threeds, name='3d', start=ip_len+1)\n",
    "# cofactor\n",
    "cos = df['Cofactor'].tolist()\n",
    "new_co_col, id2co, co2id, co_len = cofactor_processing(cos, name='co', start=threed_len+1)\n",
    "\n",
    "# make full dicts and check for no duplicates\n",
    "all_id = [id2ec, id2mf, id2bp, id2cc, id2ip, id2threed, id2co]\n",
    "all_label = [ec2id, mf2id, bp2id, cc2id, ip2id, threed2id, co2id]\n",
    "\n",
    "id2label, label2id = {}, {}\n",
    "\n",
    "key_counts = 0\n",
    "for d in all_id:\n",
    "    key_counts += len(d.keys())\n",
    "    id2label.update(d)\n",
    "print(key_counts)\n",
    "\n",
    "key_counts = 0\n",
    "for d in all_label:\n",
    "    key_counts += len(d.keys())\n",
    "    label2id.update(d)\n",
    "print(key_counts)\n",
    "\n",
    "for k, v in id2label.items():\n",
    "    if k != label2id[v]:\n",
    "        print(v)\n",
    "\n",
    "for k, v in label2id.items():\n",
    "    if k != id2label[v]:\n",
    "        print(v)\n",
    "\n",
    "print(len(id2label.keys()), len(label2id.keys()))\n",
    "\n",
    "all_cols = [new_ec_col, new_mf_col, new_bp_col, new_cc_col, new_ip_col, new_threed_col, new_co_col]\n",
    "\n",
    "df_final = replace_df(df, all_cols)\n",
    "\n",
    "print(len(df_final))\n",
    "\n",
    "df_final.to_csv('processed_swiss_prot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34747\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8118741322f34887b54e4818de843c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34560\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b9d64a250d406daa15216f77f8099d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ec make dicts:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9c2e46b88449ccbd20fce7bcd344de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ec make new column:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56092b469de04f5e8425a9bed1158520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mf make dicts:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8411929587d04c05afad68a7131310ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mf make new column:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4733a24a45994003b512fbbafaf997aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bp make dicts:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea8b4b83de94ce8923a290458ed21cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bp make new column:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0993904f3b2484599812b4a148f7e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cc make dicts:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2d129906bf41eb8110594f9073288a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cc make new column:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b78a45c3744606a3bbe440c13830a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ip make dicts:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7d24660e1c427a9446674c76742f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ip make new column:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bd3208ea5b41b5af6b3205284ff0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3d make dicts:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1833a3286e475384ecab6867dfde91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3d make new column:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d76b9401284766885c87060f7c9ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "co make dicts:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2573f991b44f83b93b1343564fd900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "co make new column:   0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc5c500c9d248e6bd7c4c0547889fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "df = load_df('trembl_all_aspects_raw.tsv')\n",
    "# EC\n",
    "ecs = df['EC'].tolist()\n",
    "new_ec_col, id2ec, ec2id, ec_len = ec_processing(ecs, name='ec', start=1)\n",
    "# MF\n",
    "mfs = df['MF'].tolist()\n",
    "new_mf_col, id2mf, mf2id, mf_len = go_processing(mfs, name='mf', start=ec_len+1)\n",
    "# BP\n",
    "bps = df['BP'].tolist()\n",
    "new_bp_col, id2bp, bp2id, bp_len = go_processing(bps, name='bp', start=mf_len+1)\n",
    "# CC\n",
    "ccs = df['CC'].tolist()\n",
    "new_cc_col, id2cc, cc2id, cc_len = go_processing(ccs, name='cc', start=bp_len+1)\n",
    "# IP\n",
    "ips = df['IP'].tolist()\n",
    "new_ip_col, id2ip, ip2id, ip_len = domain_processing(ips, name='ip', start=cc_len+1)\n",
    "# 3D\n",
    "threeds = df['3D'].tolist()\n",
    "new_threed_col, id2threed, threed2id, threed_len = domain_processing(threeds, name='3d', start=ip_len+1)\n",
    "# cofactor\n",
    "cos = df['Cofactor'].tolist()\n",
    "new_co_col, id2co, co2id, co_len = cofactor_processing(cos, name='co', start=threed_len+1)\n",
    "\n",
    "\n",
    "all_cols = [new_ec_col, new_mf_col, new_bp_col, new_cc_col, new_ip_col, new_threed_col, new_co_col]\n",
    "df = replace_df(df, all_cols)\n",
    "\n",
    "# remove dups\n",
    "for col in df.columns:\n",
    "    mask = df[col].apply(lambda x: x != [0]\n",
    "                        and (not isinstance(x, list) or len(x) > 0)\n",
    "                        and (not isinstance(x, str) or x.strip() != '[]'))\n",
    "    df = df.loc[mask]\n",
    "\n",
    "print(len(df))\n",
    "df.to_csv('processed_trembl.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>seqs</th>\n",
       "      <th>EC</th>\n",
       "      <th>Cofactor</th>\n",
       "      <th>BP</th>\n",
       "      <th>CC</th>\n",
       "      <th>MF</th>\n",
       "      <th>IP</th>\n",
       "      <th>3D</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q63673</td>\n",
       "      <td>MLLLLARCFLVALASSLLVCPGLACGPGRGFGKRQHPKKLTPLAYK...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[19651, 20201, 20080, 13621, 11650, 20079, 141...</td>\n",
       "      <td>[27633, 27433, 27634, 27175, 27181, 27701, 270...</td>\n",
       "      <td>[5744, 11169, 5759, 8412, 5577, 5858, 5877]</td>\n",
       "      <td>[30625, 30709, 35801, 29610, 31986, 31987, 491...</td>\n",
       "      <td>[57098, 56131]</td>\n",
       "      <td>{20996, 19973, 20485, 13322, 11790, 22031, 230...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Entry                                               seqs   EC Cofactor  \\\n",
       "0  Q63673  MLLLLARCFLVALASSLLVCPGLACGPGRGFGKRQHPKKLTPLAYK...  [0]      [0]   \n",
       "\n",
       "                                                  BP  \\\n",
       "0  [19651, 20201, 20080, 13621, 11650, 20079, 141...   \n",
       "\n",
       "                                                  CC  \\\n",
       "0  [27633, 27433, 27634, 27175, 27181, 27701, 270...   \n",
       "\n",
       "                                            MF  \\\n",
       "0  [5744, 11169, 5759, 8412, 5577, 5858, 5877]   \n",
       "\n",
       "                                                  IP              3D  \\\n",
       "0  [30625, 30709, 35801, 29610, 31986, 31987, 491...  [57098, 56131]   \n",
       "\n",
       "                                            combined  \n",
       "0  {20996, 19973, 20485, 13322, 11790, 22031, 230...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading previously processed\n",
    "\n",
    "df = pd.read_csv('processed_swiss_prot.csv', converters={\n",
    "    'EC': literal_eval,\n",
    "    'Cofactor': literal_eval,\n",
    "    'MF': literal_eval,\n",
    "    'BP': literal_eval,\n",
    "    'CC': literal_eval,\n",
    "    'IP': literal_eval,\n",
    "    '3D': literal_eval,\n",
    "    'combined': literal_eval\n",
    "})\n",
    "\n",
    "df['combined'] = df['combined'].apply(set)\n",
    "#df['EC'] = df['EC'].apply(set)\n",
    "#df['Cofactor'] = df['Cofactor'].apply(set)\n",
    "#df['MF'] = df['MF'].apply(set)\n",
    "#df['BP'] = df['BP'].apply(set)\n",
    "#df['CC'] = df['CC'].apply(set)\n",
    "#df['IP'] = df['IP'].apply(set)\n",
    "#df['3D'] = df['3D'].apply(set)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46b9c82f9e64287bd4cdd8c5ffcce3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sets = df['combined'].tolist()\n",
    "\n",
    "n = len(sets)\n",
    "all_indices = set(range(n))\n",
    "aspect_dict = defaultdict(set)\n",
    "\n",
    "for i, s in tqdm(enumerate(sets), total=n):\n",
    "    for item in s:\n",
    "        aspect_dict[item].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ec7c1cb7ae489287ba4a9561c0a78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "triplets = {\n",
    "    'EC': [],\n",
    "    'Cofactor': [],\n",
    "    'MF': [],\n",
    "    'BP': [],\n",
    "    'CC': [],\n",
    "    'IP': [],\n",
    "    '3D': []\n",
    "}\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    p = row['seqs']\n",
    "    \n",
    "    for aspect in triplets.keys():\n",
    "        item = random.choice(row[aspect])\n",
    "        if item != 0:\n",
    "            item_idxs = aspect_dict[item] - {i}\n",
    "            if len(item_idxs) > 0:\n",
    "                a_idx = random.choice(tuple(item_idxs))\n",
    "                a_item = df.loc[a_idx, 'seqs']\n",
    "                \n",
    "                n_idx = random.choice(tuple(all_indices - item_idxs))\n",
    "                n_item = df.loc[n_idx, 'seqs']\n",
    "                \n",
    "                triplets[aspect].append((p, a_item, n_item))\n",
    "                \n",
    "                # If aspect == 'cofactor', repeat 5 times\n",
    "                if aspect == 'cofactor':\n",
    "                    for _ in range(4):\n",
    "                        a_idx = random.choice(tuple(item_idxs))\n",
    "                        a_item = df.loc[a_idx, 'seqs']\n",
    "                        \n",
    "                        n_idx = random.choice(tuple(all_indices - item_idxs))\n",
    "                        n_item = df.loc[n_idx, 'seqs']\n",
    "                        \n",
    "                        triplets[aspect].append((p, a_item, n_item))\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85676\n",
      "13874\n",
      "93961\n",
      "94153\n",
      "94589\n",
      "90626\n",
      "94044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['positives', 'anchors', 'negatives', 'aspects'],\n",
       "    num_rows: 566923\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(triplets.items()):\n",
    "    print(len(v))\n",
    "\n",
    "ps, ans, ns, acs = [], [], [], []\n",
    "for i, (k, v) in enumerate(triplets.items()):\n",
    "    for trip in v:\n",
    "        p, a, n = trip\n",
    "        ps.append(p)\n",
    "        ans.append(a)\n",
    "        ns.append(n)\n",
    "        acs.append(i)\n",
    "\n",
    "data = Dataset.from_dict({\n",
    "    'positives':ps,\n",
    "    'anchors':ans,\n",
    "    'negatives':ns,\n",
    "    'aspects':acs\n",
    "})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8522e78c2440309ed4644e108e56f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7869cd60ffcd41acb594975dfd92af7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/284 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad67d94bd7149ceb6a3626930cb7216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/284 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585e3b90e0ea4d068df97b83f7a5415c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/493 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/lhallee/triplets/commit/8990fb7d6b4aa3fff5ff9effd82d0eea3fe9702f', commit_message='Upload dataset', commit_description='', oid='8990fb7d6b4aa3fff5ff9effd82d0eea3fe9702f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.push_to_hub('lhallee/triplets', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('triplets_epoch_1.pkl', 'wb') as f:\n",
    "    pickle.dump(triplets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For looking / documenting swiss prot duplicates\n",
    "seqs = df['seqs'].tolist()\n",
    "entry_ids = df['Entry'].tolist()\n",
    "print(len(seqs), len(list(set(seqs))))\n",
    "\n",
    "counts = {}\n",
    "duplicates = {}\n",
    "\n",
    "for i, seq in enumerate(seqs):\n",
    "    if seq in counts:\n",
    "        counts[seq] += 1\n",
    "        duplicates[seq].append(entry_ids[i])\n",
    "    else:\n",
    "        counts[seq] = 1\n",
    "        duplicates[seq] = [entry_ids[i]]\n",
    "\n",
    "# Write duplicates to a text file\n",
    "with open(\"swiss_prot_duplicates.txt\", \"w\") as file:\n",
    "    for seq, ids in duplicates.items():\n",
    "        if len(ids) > 1:\n",
    "            count = len(ids)\n",
    "            file.write(f\"{count}\\t{' '.join(ids)}\\n\")\n",
    "            file.write(f\"{seq}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
