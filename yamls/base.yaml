general_args:
  model_path: 'allenai/scibert_scivocab_uncased'
  ESM: false # ESM or BERT
  model_type: 'SentenceSimilarity'

  moe_type: 'topk'
  MOE: true 
  token_moe: false

  contact_head: false

  num_experts: 8  # Number of experts
  topk: 2  # Number of experts per block
  num_tasks: 2  # Number of tasks for MulitTask learning
  dropout: 0.05  # Dropout rate for the model
  contrastive_loss: clip
  MI_loss: false

  new_special_tokens: true  # Add new special tokens for each domain token seeded with CLS
  domains:  # List of domain tags
    - '[CAN]'
  
  wBAL: !!float 0.1
  wMI: !!float 0.1


#data_settings:
  data_paths:  # Paths to the datasets
    - 'lhallee/abstract_domain_skincancer'
  a_col: 'a'  # First feature column name in datasets
  b_col: 'b'  # Second feature column name in datasets
  label_col: 'label'  # Label column name in datasets
  max_length: 512  # Maximum length of the sequences


#id_settings:
  wandb_api_key: null # Weights and biases API key
  hf_token: null # Hugging Face API key
  hf_username: 'lhallee'  # Hugging Face username

#misc:
  project_name: 'SciMOE'  # Name of the project
  log_path: './results.txt'  # Path to save the log file
  weight_path: './best_model.pt'  # Path to the model weights to load

  patience: 3
  limits: false  # Lets user define limits for F1max


training_args:
  output_dir: !!str ./output
  logging_dir: !!str ./logs
  report_to: null

  per_device_train_batch_size: !!int 20
  per_device_eval_batch_size: !!int 20
  gradient_accumulation_steps: !!int 1
  learning_rate: !!float 1e-5
  lr_scheduler_type: !!str cosine
  weight_decay: !!float 0.01

  num_train_epochs: !!int 10
  warmup_ratio: !!float 0.0
  warmup_steps: !!int 500

  save_strategy: !!str steps
  save_steps: !!int 2500
  save_total_limit: !!int 3

  evaluation_strategy: !!str steps
  eval_steps: 2500

  logging_strategy: steps
  logging_steps: !!int 500

  bf16: false
  fp16: false

  seed: !!int 42

  eval_accumulation_steps: null
  group_by_length: false
  length_column_name: !!str length
  save_safetensors: true
  metric_for_best_model: !!str loss
