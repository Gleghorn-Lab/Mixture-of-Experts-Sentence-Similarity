{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run local_prot_vec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py --yaml_path yamls/protein_vec.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def are_models_equal(model1, model2):\n",
    "    state_dict1 = model1.state_dict()\n",
    "    state_dict2 = model2.state_dict()\n",
    "    \n",
    "    if len(state_dict1) != len(state_dict2):\n",
    "        print('Length')\n",
    "        return False\n",
    "    \n",
    "    for key in state_dict1:\n",
    "        if key not in state_dict2:\n",
    "            print('Key')\n",
    "            return False\n",
    "        \n",
    "        if not torch.equal(state_dict1[key], state_dict2[key]):\n",
    "            print('Equal')\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "if are_models_equal(disk_model.cpu(), hf_model.cpu()):\n",
    "    print(\"The models are equal.\")\n",
    "else:\n",
    "    print(\"The models are not equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.load_data import get_datasets_test_triplet\n",
    "from transformers import T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data_paths': ['lhallee/triplets'],\n",
    "    'domains': ['[EC]', '[CC]', '[MF]', '[BP]', '[CC]', '[CC]', '[IP]'],\n",
    "    'new_special_tokens': False,\n",
    "    'max_length':512, \n",
    "    'p_col': 'positives',\n",
    "    'a_col': 'anchors',\n",
    "    'n_col': 'negatives',\n",
    "    'label_col': 'aspects',\n",
    "    'model_type': 'ProteinVec'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('lhallee/ProteinVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_datasets = get_datasets_test_triplet(args, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = triplet_datasets[0]\n",
    "ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.modeling_moesm import EsmExpert\n",
    "\n",
    "\n",
    "class SentenceEnforcedSwitchMoeBlock(nn.Module): ### Test\n",
    "    def __init__(self, config, expert):\n",
    "        \"\"\"\n",
    "        Sentence level MoE, single expert chosen\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_dim = config.hidden_size\n",
    "        self.num_experts = config.num_experts\n",
    "        self.experts = nn.ModuleList([expert(config) for _ in range(self.num_experts)])\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, router_labels: torch.tensor) -> torch.Tensor:\n",
    "        # (batch, seq_len, hidden_size), (batch,) -> from 0 to num_experts-1\n",
    "        sorted_indices = torch.argsort(router_labels) # sort in order of expert idx\n",
    "        hidden_states = hidden_states[sorted_indices] # apply sort\n",
    "        router_labels = router_labels[sorted_indices] # apply sort\n",
    "        expert_idxs = torch.unique(router_labels) # find all experts needed\n",
    "        grouped_hidden_states = torch.split(hidden_states, tuple(torch.bincount(router_labels))) # split sorted hidden_states\n",
    "\n",
    "        expert_outputs = []\n",
    "        for idx, group in zip(expert_idxs, grouped_hidden_states):\n",
    "            expert_output = self.experts[idx](group) # sne batched groups to their experts\n",
    "            expert_outputs.append(expert_output)\n",
    "\n",
    "        concatenated_outputs = torch.cat(expert_outputs, dim=0)\n",
    "        final_hidden_states = concatenated_outputs[torch.argsort(sorted_indices)] # put back to original order\n",
    "        return final_hidden_states  # (batch, sequence_length, hidden_dim)\n",
    "    \n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.hidden_size = 128\n",
    "        self.num_experts = 4\n",
    "        self.intermediate_size = 256\n",
    "        self.hidden_dropout_prob = 0.0\n",
    "\n",
    "\n",
    "config = Config()\n",
    "moe_block = SentenceEnforcedSwitchMoeBlock(config, EsmExpert)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random tensors for testing\n",
    "batch_size = 8\n",
    "seq_length = 16\n",
    "hidden_size = config.hidden_size\n",
    "\n",
    "hidden_states = torch.randn(batch_size, seq_length, hidden_size)\n",
    "router_labels = torch.randint(0, config.num_experts, (batch_size,))\n",
    "\n",
    "# Test the forward pass of the SentenceEnforcedSwitchMoeBlock\n",
    "output = moe_block(hidden_states, router_labels)\n",
    "\n",
    "# Print the shapes of input and output tensors\n",
    "print(\"Input hidden states shape:\", hidden_states.shape)\n",
    "print(\"Router labels shape:\", router_labels.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_labels = torch.tensor([2, 0, 1, 2, 1])\n",
    "print(router_labels)\n",
    "sorted_indices = torch.argsort(router_labels)\n",
    "\n",
    "sorted_labels = router_labels[sorted_indices]\n",
    "\n",
    "unsorted_indices = torch.argsort(sorted_indices)\n",
    "\n",
    "router_labels = sorted_labels[unsorted_indices]\n",
    "print(router_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
