{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main --yaml_path yamls/protein_vec.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py --eval --yaml_path yamls/benchmarking/esm_sim_benchmark_8.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py --eval --yaml_path yamls/benchmarking/esm_sim_benchmark_35.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py --eval --yaml_path yamls/benchmarking/esm_sim_benchmark_150.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py --eval --yaml_path yamls/benchmarking/esm_sim_benchmark_650.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from models.model_zoo import *\n",
    "from utils import get_yaml\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yargs = get_yaml('yamls/SE/cvd.yaml')\n",
    "config = BertConfig.from_pretrained(yargs['general_args']['model_path'])\n",
    "for key, value in yargs['general_args'].items(): # copy yaml config into args\n",
    "    setattr(config, key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [path.replace('\\\\', '/') for path in glob('./weights/*.pt')]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for weight in weights:\n",
    "    model = torch.load(weight)\n",
    "    try:\n",
    "        model.config = model.bert.config\n",
    "    except:\n",
    "        print(weight)\n",
    "        continue\n",
    "    path = 'lhallee/' + weight.split('/')[-1].split('.pt')[0]\n",
    "    paths.append(path)\n",
    "    #model.push_to_hub(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('results/NLP_MOE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    tokenizer.push_to_hub(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('lhallee/sci_moe_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub('lhallee/all_nlp_singlemoe_MI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.protein_vec.src_run.huggingface_protein_vec import ProteinVec, ProteinVecConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_model = ProteinVec(config=ProteinVecConfig())\n",
    "disk_model.load_from_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.load('models/protein_vec/src_run/protein_vec_models/protein_vec.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.layers.0.self_attn.in_proj_weight\n",
      "encoder.layers.0.self_attn.in_proj_bias\n",
      "encoder.layers.0.self_attn.out_proj.weight\n",
      "encoder.layers.0.self_attn.out_proj.bias\n",
      "encoder.layers.0.linear1.weight\n",
      "encoder.layers.0.linear1.bias\n",
      "encoder.layers.0.linear2.weight\n",
      "encoder.layers.0.linear2.bias\n",
      "encoder.layers.0.norm1.weight\n",
      "encoder.layers.0.norm1.bias\n",
      "encoder.layers.0.norm2.weight\n",
      "encoder.layers.0.norm2.bias\n",
      "encoder.layers.1.self_attn.in_proj_weight\n",
      "encoder.layers.1.self_attn.in_proj_bias\n",
      "encoder.layers.1.self_attn.out_proj.weight\n",
      "encoder.layers.1.self_attn.out_proj.bias\n",
      "encoder.layers.1.linear1.weight\n",
      "encoder.layers.1.linear1.bias\n",
      "encoder.layers.1.linear2.weight\n",
      "encoder.layers.1.linear2.bias\n",
      "encoder.layers.1.norm1.weight\n",
      "encoder.layers.1.norm1.bias\n",
      "encoder.layers.1.norm2.weight\n",
      "encoder.layers.1.norm2.bias\n",
      "mlp_1.weight\n",
      "mlp_1.bias\n",
      "mlp_2.weight\n",
      "mlp_2.bias\n",
      "model_aspect_tmvec.encoder.layers.0.self_attn.in_proj_weight\n",
      "model_aspect_tmvec.encoder.layers.0.self_attn.in_proj_bias\n",
      "model_aspect_tmvec.encoder.layers.0.self_attn.out_proj.weight\n",
      "model_aspect_tmvec.encoder.layers.0.self_attn.out_proj.bias\n",
      "model_aspect_tmvec.encoder.layers.0.linear1.weight\n",
      "model_aspect_tmvec.encoder.layers.0.linear1.bias\n",
      "model_aspect_tmvec.encoder.layers.0.linear2.weight\n",
      "model_aspect_tmvec.encoder.layers.0.linear2.bias\n",
      "model_aspect_tmvec.encoder.layers.0.norm1.weight\n",
      "model_aspect_tmvec.encoder.layers.0.norm1.bias\n",
      "model_aspect_tmvec.encoder.layers.0.norm2.weight\n",
      "model_aspect_tmvec.encoder.layers.0.norm2.bias\n",
      "model_aspect_tmvec.encoder.layers.1.self_attn.in_proj_weight\n",
      "model_aspect_tmvec.encoder.layers.1.self_attn.in_proj_bias\n",
      "model_aspect_tmvec.encoder.layers.1.self_attn.out_proj.weight\n",
      "model_aspect_tmvec.encoder.layers.1.self_attn.out_proj.bias\n",
      "model_aspect_tmvec.encoder.layers.1.linear1.weight\n",
      "model_aspect_tmvec.encoder.layers.1.linear1.bias\n",
      "model_aspect_tmvec.encoder.layers.1.linear2.weight\n",
      "model_aspect_tmvec.encoder.layers.1.linear2.bias\n",
      "model_aspect_tmvec.encoder.layers.1.norm1.weight\n",
      "model_aspect_tmvec.encoder.layers.1.norm1.bias\n",
      "model_aspect_tmvec.encoder.layers.1.norm2.weight\n",
      "model_aspect_tmvec.encoder.layers.1.norm2.bias\n",
      "model_aspect_tmvec.encoder.layers.2.self_attn.in_proj_weight\n",
      "model_aspect_tmvec.encoder.layers.2.self_attn.in_proj_bias\n",
      "model_aspect_tmvec.encoder.layers.2.self_attn.out_proj.weight\n",
      "model_aspect_tmvec.encoder.layers.2.self_attn.out_proj.bias\n",
      "model_aspect_tmvec.encoder.layers.2.linear1.weight\n",
      "model_aspect_tmvec.encoder.layers.2.linear1.bias\n",
      "model_aspect_tmvec.encoder.layers.2.linear2.weight\n",
      "model_aspect_tmvec.encoder.layers.2.linear2.bias\n",
      "model_aspect_tmvec.encoder.layers.2.norm1.weight\n",
      "model_aspect_tmvec.encoder.layers.2.norm1.bias\n",
      "model_aspect_tmvec.encoder.layers.2.norm2.weight\n",
      "model_aspect_tmvec.encoder.layers.2.norm2.bias\n",
      "model_aspect_tmvec.encoder.layers.3.self_attn.in_proj_weight\n",
      "model_aspect_tmvec.encoder.layers.3.self_attn.in_proj_bias\n",
      "model_aspect_tmvec.encoder.layers.3.self_attn.out_proj.weight\n",
      "model_aspect_tmvec.encoder.layers.3.self_attn.out_proj.bias\n",
      "model_aspect_tmvec.encoder.layers.3.linear1.weight\n",
      "model_aspect_tmvec.encoder.layers.3.linear1.bias\n",
      "model_aspect_tmvec.encoder.layers.3.linear2.weight\n",
      "model_aspect_tmvec.encoder.layers.3.linear2.bias\n",
      "model_aspect_tmvec.encoder.layers.3.norm1.weight\n",
      "model_aspect_tmvec.encoder.layers.3.norm1.bias\n",
      "model_aspect_tmvec.encoder.layers.3.norm2.weight\n",
      "model_aspect_tmvec.encoder.layers.3.norm2.bias\n",
      "model_aspect_tmvec.mlp.weight\n",
      "model_aspect_tmvec.mlp.bias\n",
      "model_aspect_pfam.encoder.layers.0.self_attn.in_proj_weight\n",
      "model_aspect_pfam.encoder.layers.0.self_attn.in_proj_bias\n",
      "model_aspect_pfam.encoder.layers.0.self_attn.out_proj.weight\n",
      "model_aspect_pfam.encoder.layers.0.self_attn.out_proj.bias\n",
      "model_aspect_pfam.encoder.layers.0.linear1.weight\n",
      "model_aspect_pfam.encoder.layers.0.linear1.bias\n",
      "model_aspect_pfam.encoder.layers.0.linear2.weight\n",
      "model_aspect_pfam.encoder.layers.0.linear2.bias\n",
      "model_aspect_pfam.encoder.layers.0.norm1.weight\n",
      "model_aspect_pfam.encoder.layers.0.norm1.bias\n",
      "model_aspect_pfam.encoder.layers.0.norm2.weight\n",
      "model_aspect_pfam.encoder.layers.0.norm2.bias\n",
      "model_aspect_pfam.encoder.layers.1.self_attn.in_proj_weight\n",
      "model_aspect_pfam.encoder.layers.1.self_attn.in_proj_bias\n",
      "model_aspect_pfam.encoder.layers.1.self_attn.out_proj.weight\n",
      "model_aspect_pfam.encoder.layers.1.self_attn.out_proj.bias\n",
      "model_aspect_pfam.encoder.layers.1.linear1.weight\n",
      "model_aspect_pfam.encoder.layers.1.linear1.bias\n",
      "model_aspect_pfam.encoder.layers.1.linear2.weight\n",
      "model_aspect_pfam.encoder.layers.1.linear2.bias\n",
      "model_aspect_pfam.encoder.layers.1.norm1.weight\n",
      "model_aspect_pfam.encoder.layers.1.norm1.bias\n",
      "model_aspect_pfam.encoder.layers.1.norm2.weight\n",
      "model_aspect_pfam.encoder.layers.1.norm2.bias\n",
      "model_aspect_pfam.mlp_1.weight\n",
      "model_aspect_pfam.mlp_1.bias\n",
      "model_aspect_pfam.mlp_2.weight\n",
      "model_aspect_pfam.mlp_2.bias\n",
      "model_aspect_gene3D.encoder.layers.0.self_attn.in_proj_weight\n",
      "model_aspect_gene3D.encoder.layers.0.self_attn.in_proj_bias\n",
      "model_aspect_gene3D.encoder.layers.0.self_attn.out_proj.weight\n",
      "model_aspect_gene3D.encoder.layers.0.self_attn.out_proj.bias\n",
      "model_aspect_gene3D.encoder.layers.0.linear1.weight\n",
      "model_aspect_gene3D.encoder.layers.0.linear1.bias\n",
      "model_aspect_gene3D.encoder.layers.0.linear2.weight\n",
      "model_aspect_gene3D.encoder.layers.0.linear2.bias\n",
      "model_aspect_gene3D.encoder.layers.0.norm1.weight\n",
      "model_aspect_gene3D.encoder.layers.0.norm1.bias\n",
      "model_aspect_gene3D.encoder.layers.0.norm2.weight\n",
      "model_aspect_gene3D.encoder.layers.0.norm2.bias\n",
      "model_aspect_gene3D.encoder.layers.1.self_attn.in_proj_weight\n",
      "model_aspect_gene3D.encoder.layers.1.self_attn.in_proj_bias\n",
      "model_aspect_gene3D.encoder.layers.1.self_attn.out_proj.weight\n",
      "model_aspect_gene3D.encoder.layers.1.self_attn.out_proj.bias\n",
      "model_aspect_gene3D.encoder.layers.1.linear1.weight\n",
      "model_aspect_gene3D.encoder.layers.1.linear1.bias\n",
      "model_aspect_gene3D.encoder.layers.1.linear2.weight\n",
      "model_aspect_gene3D.encoder.layers.1.linear2.bias\n",
      "model_aspect_gene3D.encoder.layers.1.norm1.weight\n",
      "model_aspect_gene3D.encoder.layers.1.norm1.bias\n",
      "model_aspect_gene3D.encoder.layers.1.norm2.weight\n",
      "model_aspect_gene3D.encoder.layers.1.norm2.bias\n",
      "model_aspect_gene3D.mlp_1.weight\n",
      "model_aspect_gene3D.mlp_1.bias\n",
      "model_aspect_gene3D.mlp_2.weight\n",
      "model_aspect_gene3D.mlp_2.bias\n",
      "model_aspect_ec.encoder.layers.0.self_attn.in_proj_weight\n",
      "model_aspect_ec.encoder.layers.0.self_attn.in_proj_bias\n",
      "model_aspect_ec.encoder.layers.0.self_attn.out_proj.weight\n",
      "model_aspect_ec.encoder.layers.0.self_attn.out_proj.bias\n",
      "model_aspect_ec.encoder.layers.0.linear1.weight\n",
      "model_aspect_ec.encoder.layers.0.linear1.bias\n",
      "model_aspect_ec.encoder.layers.0.linear2.weight\n",
      "model_aspect_ec.encoder.layers.0.linear2.bias\n",
      "model_aspect_ec.encoder.layers.0.norm1.weight\n",
      "model_aspect_ec.encoder.layers.0.norm1.bias\n",
      "model_aspect_ec.encoder.layers.0.norm2.weight\n",
      "model_aspect_ec.encoder.layers.0.norm2.bias\n",
      "model_aspect_ec.encoder.layers.1.self_attn.in_proj_weight\n",
      "model_aspect_ec.encoder.layers.1.self_attn.in_proj_bias\n",
      "model_aspect_ec.encoder.layers.1.self_attn.out_proj.weight\n",
      "model_aspect_ec.encoder.layers.1.self_attn.out_proj.bias\n",
      "model_aspect_ec.encoder.layers.1.linear1.weight\n",
      "model_aspect_ec.encoder.layers.1.linear1.bias\n",
      "model_aspect_ec.encoder.layers.1.linear2.weight\n",
      "model_aspect_ec.encoder.layers.1.linear2.bias\n",
      "model_aspect_ec.encoder.layers.1.norm1.weight\n",
      "model_aspect_ec.encoder.layers.1.norm1.bias\n",
      "model_aspect_ec.encoder.layers.1.norm2.weight\n",
      "model_aspect_ec.encoder.layers.1.norm2.bias\n",
      "model_aspect_ec.mlp_1.weight\n",
      "model_aspect_ec.mlp_1.bias\n",
      "model_aspect_ec.mlp_2.weight\n",
      "model_aspect_ec.mlp_2.bias\n",
      "model_aspect_mfo.encoder.layers.0.self_attn.in_proj_weight\n",
      "model_aspect_mfo.encoder.layers.0.self_attn.in_proj_bias\n",
      "model_aspect_mfo.encoder.layers.0.self_attn.out_proj.weight\n",
      "model_aspect_mfo.encoder.layers.0.self_attn.out_proj.bias\n",
      "model_aspect_mfo.encoder.layers.0.linear1.weight\n",
      "model_aspect_mfo.encoder.layers.0.linear1.bias\n",
      "model_aspect_mfo.encoder.layers.0.linear2.weight\n",
      "model_aspect_mfo.encoder.layers.0.linear2.bias\n",
      "model_aspect_mfo.encoder.layers.0.norm1.weight\n",
      "model_aspect_mfo.encoder.layers.0.norm1.bias\n",
      "model_aspect_mfo.encoder.layers.0.norm2.weight\n",
      "model_aspect_mfo.encoder.layers.0.norm2.bias\n",
      "model_aspect_mfo.encoder.layers.1.self_attn.in_proj_weight\n",
      "model_aspect_mfo.encoder.layers.1.self_attn.in_proj_bias\n",
      "model_aspect_mfo.encoder.layers.1.self_attn.out_proj.weight\n",
      "model_aspect_mfo.encoder.layers.1.self_attn.out_proj.bias\n",
      "model_aspect_mfo.encoder.layers.1.linear1.weight\n",
      "model_aspect_mfo.encoder.layers.1.linear1.bias\n",
      "model_aspect_mfo.encoder.layers.1.linear2.weight\n",
      "model_aspect_mfo.encoder.layers.1.linear2.bias\n",
      "model_aspect_mfo.encoder.layers.1.norm1.weight\n",
      "model_aspect_mfo.encoder.layers.1.norm1.bias\n",
      "model_aspect_mfo.encoder.layers.1.norm2.weight\n",
      "model_aspect_mfo.encoder.layers.1.norm2.bias\n",
      "model_aspect_mfo.encoder.layers.2.self_attn.in_proj_weight\n",
      "model_aspect_mfo.encoder.layers.2.self_attn.in_proj_bias\n",
      "model_aspect_mfo.encoder.layers.2.self_attn.out_proj.weight\n",
      "model_aspect_mfo.encoder.layers.2.self_attn.out_proj.bias\n",
      "model_aspect_mfo.encoder.layers.2.linear1.weight\n",
      "model_aspect_mfo.encoder.layers.2.linear1.bias\n",
      "model_aspect_mfo.encoder.layers.2.linear2.weight\n",
      "model_aspect_mfo.encoder.layers.2.linear2.bias\n",
      "model_aspect_mfo.encoder.layers.2.norm1.weight\n",
      "model_aspect_mfo.encoder.layers.2.norm1.bias\n",
      "model_aspect_mfo.encoder.layers.2.norm2.weight\n",
      "model_aspect_mfo.encoder.layers.2.norm2.bias\n",
      "model_aspect_mfo.encoder.layers.3.self_attn.in_proj_weight\n",
      "model_aspect_mfo.encoder.layers.3.self_attn.in_proj_bias\n",
      "model_aspect_mfo.encoder.layers.3.self_attn.out_proj.weight\n",
      "model_aspect_mfo.encoder.layers.3.self_attn.out_proj.bias\n",
      "model_aspect_mfo.encoder.layers.3.linear1.weight\n",
      "model_aspect_mfo.encoder.layers.3.linear1.bias\n",
      "model_aspect_mfo.encoder.layers.3.linear2.weight\n",
      "model_aspect_mfo.encoder.layers.3.linear2.bias\n",
      "model_aspect_mfo.encoder.layers.3.norm1.weight\n",
      "model_aspect_mfo.encoder.layers.3.norm1.bias\n",
      "model_aspect_mfo.encoder.layers.3.norm2.weight\n",
      "model_aspect_mfo.encoder.layers.3.norm2.bias\n",
      "model_aspect_mfo.mlp_1.weight\n",
      "model_aspect_mfo.mlp_1.bias\n",
      "model_aspect_mfo.mlp_2.weight\n",
      "model_aspect_mfo.mlp_2.bias\n",
      "model_aspect_bpo.encoder.layers.0.self_attn.in_proj_weight\n",
      "model_aspect_bpo.encoder.layers.0.self_attn.in_proj_bias\n",
      "model_aspect_bpo.encoder.layers.0.self_attn.out_proj.weight\n",
      "model_aspect_bpo.encoder.layers.0.self_attn.out_proj.bias\n",
      "model_aspect_bpo.encoder.layers.0.linear1.weight\n",
      "model_aspect_bpo.encoder.layers.0.linear1.bias\n",
      "model_aspect_bpo.encoder.layers.0.linear2.weight\n",
      "model_aspect_bpo.encoder.layers.0.linear2.bias\n",
      "model_aspect_bpo.encoder.layers.0.norm1.weight\n",
      "model_aspect_bpo.encoder.layers.0.norm1.bias\n",
      "model_aspect_bpo.encoder.layers.0.norm2.weight\n",
      "model_aspect_bpo.encoder.layers.0.norm2.bias\n",
      "model_aspect_bpo.encoder.layers.1.self_attn.in_proj_weight\n",
      "model_aspect_bpo.encoder.layers.1.self_attn.in_proj_bias\n",
      "model_aspect_bpo.encoder.layers.1.self_attn.out_proj.weight\n",
      "model_aspect_bpo.encoder.layers.1.self_attn.out_proj.bias\n",
      "model_aspect_bpo.encoder.layers.1.linear1.weight\n",
      "model_aspect_bpo.encoder.layers.1.linear1.bias\n",
      "model_aspect_bpo.encoder.layers.1.linear2.weight\n",
      "model_aspect_bpo.encoder.layers.1.linear2.bias\n",
      "model_aspect_bpo.encoder.layers.1.norm1.weight\n",
      "model_aspect_bpo.encoder.layers.1.norm1.bias\n",
      "model_aspect_bpo.encoder.layers.1.norm2.weight\n",
      "model_aspect_bpo.encoder.layers.1.norm2.bias\n",
      "model_aspect_bpo.encoder.layers.2.self_attn.in_proj_weight\n",
      "model_aspect_bpo.encoder.layers.2.self_attn.in_proj_bias\n",
      "model_aspect_bpo.encoder.layers.2.self_attn.out_proj.weight\n",
      "model_aspect_bpo.encoder.layers.2.self_attn.out_proj.bias\n",
      "model_aspect_bpo.encoder.layers.2.linear1.weight\n",
      "model_aspect_bpo.encoder.layers.2.linear1.bias\n",
      "model_aspect_bpo.encoder.layers.2.linear2.weight\n",
      "model_aspect_bpo.encoder.layers.2.linear2.bias\n",
      "model_aspect_bpo.encoder.layers.2.norm1.weight\n",
      "model_aspect_bpo.encoder.layers.2.norm1.bias\n",
      "model_aspect_bpo.encoder.layers.2.norm2.weight\n",
      "model_aspect_bpo.encoder.layers.2.norm2.bias\n",
      "model_aspect_bpo.encoder.layers.3.self_attn.in_proj_weight\n",
      "model_aspect_bpo.encoder.layers.3.self_attn.in_proj_bias\n",
      "model_aspect_bpo.encoder.layers.3.self_attn.out_proj.weight\n",
      "model_aspect_bpo.encoder.layers.3.self_attn.out_proj.bias\n",
      "model_aspect_bpo.encoder.layers.3.linear1.weight\n",
      "model_aspect_bpo.encoder.layers.3.linear1.bias\n",
      "model_aspect_bpo.encoder.layers.3.linear2.weight\n",
      "model_aspect_bpo.encoder.layers.3.linear2.bias\n",
      "model_aspect_bpo.encoder.layers.3.norm1.weight\n",
      "model_aspect_bpo.encoder.layers.3.norm1.bias\n",
      "model_aspect_bpo.encoder.layers.3.norm2.weight\n",
      "model_aspect_bpo.encoder.layers.3.norm2.bias\n",
      "model_aspect_bpo.mlp_1.weight\n",
      "model_aspect_bpo.mlp_1.bias\n",
      "model_aspect_bpo.mlp_2.weight\n",
      "model_aspect_bpo.mlp_2.bias\n",
      "model_aspect_cco.encoder.layers.0.self_attn.in_proj_weight\n",
      "model_aspect_cco.encoder.layers.0.self_attn.in_proj_bias\n",
      "model_aspect_cco.encoder.layers.0.self_attn.out_proj.weight\n",
      "model_aspect_cco.encoder.layers.0.self_attn.out_proj.bias\n",
      "model_aspect_cco.encoder.layers.0.linear1.weight\n",
      "model_aspect_cco.encoder.layers.0.linear1.bias\n",
      "model_aspect_cco.encoder.layers.0.linear2.weight\n",
      "model_aspect_cco.encoder.layers.0.linear2.bias\n",
      "model_aspect_cco.encoder.layers.0.norm1.weight\n",
      "model_aspect_cco.encoder.layers.0.norm1.bias\n",
      "model_aspect_cco.encoder.layers.0.norm2.weight\n",
      "model_aspect_cco.encoder.layers.0.norm2.bias\n",
      "model_aspect_cco.encoder.layers.1.self_attn.in_proj_weight\n",
      "model_aspect_cco.encoder.layers.1.self_attn.in_proj_bias\n",
      "model_aspect_cco.encoder.layers.1.self_attn.out_proj.weight\n",
      "model_aspect_cco.encoder.layers.1.self_attn.out_proj.bias\n",
      "model_aspect_cco.encoder.layers.1.linear1.weight\n",
      "model_aspect_cco.encoder.layers.1.linear1.bias\n",
      "model_aspect_cco.encoder.layers.1.linear2.weight\n",
      "model_aspect_cco.encoder.layers.1.linear2.bias\n",
      "model_aspect_cco.encoder.layers.1.norm1.weight\n",
      "model_aspect_cco.encoder.layers.1.norm1.bias\n",
      "model_aspect_cco.encoder.layers.1.norm2.weight\n",
      "model_aspect_cco.encoder.layers.1.norm2.bias\n",
      "model_aspect_cco.encoder.layers.2.self_attn.in_proj_weight\n",
      "model_aspect_cco.encoder.layers.2.self_attn.in_proj_bias\n",
      "model_aspect_cco.encoder.layers.2.self_attn.out_proj.weight\n",
      "model_aspect_cco.encoder.layers.2.self_attn.out_proj.bias\n",
      "model_aspect_cco.encoder.layers.2.linear1.weight\n",
      "model_aspect_cco.encoder.layers.2.linear1.bias\n",
      "model_aspect_cco.encoder.layers.2.linear2.weight\n",
      "model_aspect_cco.encoder.layers.2.linear2.bias\n",
      "model_aspect_cco.encoder.layers.2.norm1.weight\n",
      "model_aspect_cco.encoder.layers.2.norm1.bias\n",
      "model_aspect_cco.encoder.layers.2.norm2.weight\n",
      "model_aspect_cco.encoder.layers.2.norm2.bias\n",
      "model_aspect_cco.encoder.layers.3.self_attn.in_proj_weight\n",
      "model_aspect_cco.encoder.layers.3.self_attn.in_proj_bias\n",
      "model_aspect_cco.encoder.layers.3.self_attn.out_proj.weight\n",
      "model_aspect_cco.encoder.layers.3.self_attn.out_proj.bias\n",
      "model_aspect_cco.encoder.layers.3.linear1.weight\n",
      "model_aspect_cco.encoder.layers.3.linear1.bias\n",
      "model_aspect_cco.encoder.layers.3.linear2.weight\n",
      "model_aspect_cco.encoder.layers.3.linear2.bias\n",
      "model_aspect_cco.encoder.layers.3.norm1.weight\n",
      "model_aspect_cco.encoder.layers.3.norm1.bias\n",
      "model_aspect_cco.encoder.layers.3.norm2.weight\n",
      "model_aspect_cco.encoder.layers.3.norm2.bias\n",
      "model_aspect_cco.mlp_1.weight\n",
      "model_aspect_cco.mlp_1.bias\n",
      "model_aspect_cco.mlp_2.weight\n",
      "model_aspect_cco.mlp_2.bias\n"
     ]
    }
   ],
   "source": [
    "for k, v in test['state_dict'].items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ProteinVec(config=ProteinVecConfig())\n",
    "model2.from_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def are_models_equal(model1, model2):\n",
    "    state_dict1 = model1.state_dict()\n",
    "    state_dict2 = model2.state_dict()\n",
    "    \n",
    "    if len(state_dict1) != len(state_dict2):\n",
    "        print('Length')\n",
    "        return False\n",
    "    \n",
    "    for key in state_dict1:\n",
    "        if key not in state_dict2:\n",
    "            print('Key')\n",
    "            return False\n",
    "        \n",
    "        if not torch.equal(state_dict1[key], state_dict2[key]):\n",
    "            print(key)\n",
    "            #return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "if are_models_equal(model.cpu(), model2.cpu()):\n",
    "    print(\"The models are equal.\")\n",
    "else:\n",
    "    print(\"The models are not equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #encoder_state_dict = OrderedDict()\n",
    "        #for key, value in state_dict.items():\n",
    "        #    if key.startswith('encoder.'):\n",
    "        #        new_key = key[len('encoder.'):]  # Remove 'encoder.' prefix\n",
    "        #        encoder_state_dict[new_key] = value\n",
    "        #    else:\n",
    "        #        encoder_state_dict[key] = value#\n",
    "        #self.moe.encoder.load_state_dict(encoder_state_dict)\n",
    "\n",
    "        self.moe.model_aspect_tmvec = trans_basic_block_tmvec.load_from_checkpoint(\n",
    "            os.path.join(aspect_path, 'tm_vec_swiss_model_large.ckpt'),\n",
    "            config=TmConfig.from_huggingface('tm', self.config)\n",
    "        )\n",
    "        self.moe.model_aspect_pfam = trans_basic_block_single.load_from_checkpoint(\n",
    "            os.path.join(aspect_path, 'aspect_vec_pfam.ckpt'),\n",
    "            config=SingleConfig.from_huggingface('pfam', self.config)\n",
    "        )\n",
    "        self.moe.model_aspect_gene3D = trans_basic_block_single.load_from_checkpoint(\n",
    "            os.path.join(aspect_path, 'aspect_vec_gene3d.ckpt'),\n",
    "            config=SingleConfig.from_huggingface('gene3d', self.config)\n",
    "        )\n",
    "        self.moe.model_aspect_ec = trans_basic_block_single.load_from_checkpoint(\n",
    "            os.path.join(aspect_path, 'aspect_vec_ec.ckpt'),\n",
    "            config=SingleConfig.from_huggingface('ec', self.config)\n",
    "        )\n",
    "        self.moe.model_aspect_mfo = trans_basic_block_single.load_from_checkpoint(\n",
    "            os.path.join(aspect_path, 'aspect_vec_go_mfo.ckpt'),\n",
    "            config=SingleConfig.from_huggingface('mf', self.config)\n",
    "        )\n",
    "        self.moe.model_aspect_bpo = trans_basic_block_single.load_from_checkpoint(\n",
    "            os.path.join(aspect_path, 'aspect_vec_go_bpo.ckpt'),\n",
    "            config=SingleConfig.from_huggingface('bp', self.config)\n",
    "        )\n",
    "        self.moe.model_aspect_cco = trans_basic_block_single.load_from_checkpoint(\n",
    "            os.path.join(aspect_path, 'aspect_vec_go_cco.ckpt'),\n",
    "            config=SingleConfig.from_huggingface('cc', self.config)\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
